# run this yml file from the CLI with: docker-compose up -d
# connect to:
# db: docker-compose exec db psql --username=svengerlach --dbname=secure_my_spot_dev
# db: docker exec -it [container name] psql --username=svengerlach --dbname=secure_my_spot_dev
# source for rabbit / redis: https://github.com/MexsonFernandes/Asynchronous_Tasks-Django-Celery-RabbitMQ-Redis/blob/master/docker-compose.yml


version: "3.8"

services:
  # django service
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.python
    image: api
    container_name: api
    command: ["sh", "scripts/run_dev.sh"]
    expose:
      - 3000
    ports:
      - "3001:3001"
    depends_on:
      - db
      - celery
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      EMAIL_USER: ${EMAIL_USER}
      EMAIL_PASSWORD: ${EMAIL_PASSWORD}
      STRIPE_API_TEST_KEY: ${STRIPE_API_TEST_KEY}
      DOPPLER_CONFIG: ${DOPPLER_CONFIG}
      CLIENT_ORIGIN: ${CLIENT_ORIGIN}
      ALLOWED_HOSTS: ${ALLOWED_HOSTS}
    networks:
      - main_network
    volumes:
      - .:/app

  # Database postgres service
  db:
    image: postgres
    container_name: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
    networks:
      - main_network
    volumes:
      - postgres_data:/var/lib/postgresql/data/

  # Celery service
  celery:
    build:
      context: .
      dockerfile: docker/Dockerfile.python
    container_name: celery
    image: celery
    # auto-reload should not be used for production
    # statedb: https://docs.celeryproject.org/en/stable/userguide/workers.html#persistent-revokes
    command: python manage.py celery_autoload
    depends_on:
      - db
      - broker
      - redis
    restart: always
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      EMAIL_USER: ${EMAIL_USER}
      EMAIL_PASSWORD: ${EMAIL_PASSWORD}
      STRIPE_API_TEST_KEY: ${STRIPE_API_TEST_KEY}
      CLIENT_ORIGIN: ${CLIENT_ORIGIN}
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      DOPPLER_CONFIG: ${DOPPLER_CONFIG}
      ALLOWED_HOSTS: ${ALLOWED_HOSTS}
    networks:
      - main_network
    volumes:
      - .:/app

  # Broker service provided by RabbitMQ
  broker:
    image: rabbitmq:3-management
    container_name: rabbit
    restart: on-failure
    ports:
      - "5672:5672"  # We forward this port because it's useful for debugging
      - "15672:15672"  # Here, we can access RabbitMQ management plugin
    networks:
      - main_network
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}

  # Backend storage service for async results provided by Redis
  redis:
    container_name: redis
    image: redis
    hostname: redis
    # use the redis_entrypoint
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    networks:
      - main_network

networks:
  main_network:

volumes:
  postgres_data: